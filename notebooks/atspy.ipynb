{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating AtsPy with Population Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6XiWa0wGiY1"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtWJCQO-OKFy"
   },
   "source": [
    "When running this notebook on Google Colab, we may have to NB Load The Package, then \"Runtime\" -> \"Restart Runtime\" For everything To load correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LKibabzFGzhA",
    "outputId": "58eda4cf-5cfa-482e-ab7e-80b2321ae09d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install atspy\n",
    "!pip install pigar\n",
    "!pip install holidays==0.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from atspy import AutomatedModel\n",
    "from scipy import stats\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.csgraph as csgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/graph.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a single data record, returns the total flow as a time series. \n",
    "def extract_timeseries(point):\n",
    "    ts = pd.Series(point[2:])\n",
    "    ts.index = pd.to_datetime(point.index[2:])\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.unique(data['source_state'])\n",
    "\n",
    "# Adjacency Matrix is a 50x50 array. \n",
    "# adjacency[s, t] = # people going from source state s to target state t\n",
    "# s and t are state \"numbers\"; ie. the index of the state in \"states\"\n",
    "adj = np.zeros((len(states), len(states)))\n",
    "\n",
    "for s, source_state in enumerate(states): \n",
    "    src_data = data.loc[data['source_state'] == source_state]\n",
    "    for t, target_state in enumerate(states): \n",
    "        entry = src_data.loc[src_data['target_state'] == target_state].iloc[0]     \n",
    "        adj[s, t] = np.sum(extract_timeseries(entry))\n",
    "\n",
    "assert adj[0, 0] == extract_timeseries(data.iloc[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ε = 5e6\n",
    "\n",
    "# connected components; 1 if connection, 0 if not. \n",
    "conn = np.zeros((len(states), len(states)))\n",
    "conn[adj > ε] = 1\n",
    "conn[adj <= ε] = 0 \n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, clusters = csgraph.connected_components(\n",
    "    csgraph=sparse.csr_matrix(conn), \n",
    "    connection='weak'\n",
    "    directed=False, \n",
    "    return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in np.unique(clusters): \n",
    "    print(f'Cluster {label}:')\n",
    "    for ind, val in enumerate(clusters): \n",
    "        if val == label: \n",
    "            print(f'\\t{states[ind]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pseudo-States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've got to augment the data of each individual state with the data from their cluster.\n",
    "\n",
    "We previously tried to do this using arithmetic averages. That didn't work. Now we need to be smarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Clustering with AtsPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AtsPy allows for several models. The pertinent model codes are:\n",
    "\n",
    "1. ```ARIMA``` - Automated ARIMA Modelling\n",
    "1. ```HWAAS``` - Exponential Smoothing With Additive Trend and Additive Seasonality\n",
    "1. ```HWAMS``` - Exponential Smoothing with Additive Trend and Multiplicative Seasonality\n",
    "\n",
    "Note that the `HWAAS` and `HWAMS` are variants of the Holt-Winters algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "cal = pd.Series.to_frame(df[df['Province_State'] == 'California']['Confirmed'])\n",
    "cal['Date'] = pd.to_datetime(df.Date)\n",
    "cal = cal.set_index(\"Date\")\n",
    "train = cal[0:112]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWfyc4ZFHMXa",
    "outputId": "5d61408d-22af-4f7a-8f8d-01b47578e264"
   },
   "outputs": [],
   "source": [
    "# HWAMS doesn't seem to do as well :(\n",
    "model_list=[\"HWAAS\"]\n",
    "results = {}\n",
    "test = {}\n",
    "for state, group in df.groupby('Province_State'):\n",
    "  print(\"Training\", state)\n",
    "  split = pd.Series.to_frame(group['Confirmed'])\n",
    "  split['Date'] = pd.to_datetime(group.Date)\n",
    "  split = split.set_index(\"Date\")\n",
    "  train = split[:112]\n",
    "  test[state] = split[112:]['cl'].values * cl[state]\n",
    "  am = AutomatedModel(df = train, model_list=model_list, forecast_len=30 )\n",
    "  forecast_out = am.forecast_outsample()\n",
    "  results[state] = forecast_out['HWAAS'].values\n",
    "\n",
    "  # for state, group in clf.groupby('Province_State'):\n",
    "  #   print(\"Training\", state)\n",
    "  #   if state not in np.unique(df['Province_State']):\n",
    "  #     split = pd.Series.to_frame(group['Confirmed'])\n",
    "  #     split['Date'] = pd.to_datetime(group.Date)\n",
    "  #     split = split.set_index(\"Date\")\n",
    "  #     train = split[:112]\n",
    "  #     test[state] = split[112:]['cl'].values * cl[state]\n",
    "  #     am = AutomatedModel(df = train, model_list=model_list, forecast_len=30 )\n",
    "  #     forecast_out = am.forecast_outsample()\n",
    "  #     results[state] = forecast_out['ARIMA'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdKZNjauyJ7M",
    "outputId": "87b124c8-6247-4948-93ff-c05668cb7752"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uexoiA-hjWYF"
   },
   "outputs": [],
   "source": [
    "def MAPE(predicted, actual):\n",
    "    assert len(predicted) == len(actual)\n",
    "    res = 0\n",
    "    for i in range(len(predicted)):\n",
    "        diff = np.abs(predicted[i] - actual[i]) / np.abs(actual[i])\n",
    "        res += diff\n",
    "    return (res/len(predicted)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zS3Pe571_OLY",
    "outputId": "e7c0264e-f022-4a74-ec23-29c76a6078bd"
   },
   "outputs": [],
   "source": [
    "mapes = []\n",
    "for state in results:\n",
    "  pred = results[state]\n",
    "  t = test[state]\n",
    "  mape = MAPE(pred, t)\n",
    "  print(state, mape)\n",
    "  mapes.append(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_rZ7-IcWCIY",
    "outputId": "4ecc50db-cae0-4758-dcba-3f6729512fb4"
   },
   "outputs": [],
   "source": [
    "total_mape = 0\n",
    "for mape in mapes:\n",
    "  total_mape += mape*30\n",
    "total_mape = total_mape/1500\n",
    "total_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6jxbY4HvFBy"
   },
   "outputs": [],
   "source": [
    "def train_full(df, model_name, param):\n",
    "  results = {}\n",
    "  for state, group in df.groupby('Province_State'):\n",
    "    print(\"Training\", state)\n",
    "    split = pd.Series.to_frame(group[param])\n",
    "    split['Date'] = pd.to_datetime(group.Date)\n",
    "    split = split.set_index(\"Date\")\n",
    "    am = AutomatedModel(df = split, model_list=[model_name], forecast_len=26 )\n",
    "    forecast_out = am.forecast_outsample()\n",
    "    results[state] = forecast_out[model_name].values\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkdt5qz4vgei",
    "outputId": "3833e75f-c2fb-4c27-8684-8d78e48d7ecf"
   },
   "outputs": [],
   "source": [
    "conf = train_full(df, 'HWAAS', \"Confirmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GVYm6lTvv7e",
    "outputId": "e6136166-7db9-4a2a-80cf-71cc47a7f94b"
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QFQYewUw9ff",
    "outputId": "2e3a49df-8e6c-46c4-d688-02d5bb77f8ae"
   },
   "outputs": [],
   "source": [
    "death = train_full(df, 'HWAAS', 'Deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnlaMm2hxBMX",
    "outputId": "ff68178a-437d-4c6e-8759-b665cbb78ef6"
   },
   "outputs": [],
   "source": [
    "death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fsTSDMwhx0sF",
    "outputId": "f24c47a4-1f8b-47a1-94f2-8e326eae5692"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "for index, state in enumerate(np.unique(df['Province_State'])):\n",
    "    predicted_cases = conf[state]\n",
    "    for j in range(len(predicted_cases)):\n",
    "        cur_index = index + j * 50\n",
    "        test['Confirmed'].iloc[cur_index] = predicted_cases[j]\n",
    "\n",
    "\n",
    "for index, state in enumerate(np.unique(df['Province_State'])):\n",
    "    predicted_cases = death[state]\n",
    "    for j in range(len(predicted_cases)):\n",
    "        cur_index = index + j * 50\n",
    "        test['Deaths'].iloc[cur_index] = predicted_cases[j]\n",
    "\n",
    "\n",
    "submission = test\n",
    "submission = submission.drop(['Province_State', 'Date'], axis = 1)\n",
    "submission.head()\n",
    "\n",
    "submission.to_csv('holt_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redividing States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've got to split the clusters back into their component states. \n",
    "\n",
    "We previously tried to do this using arithmetic averages. \n",
    "That didn't work. \n",
    "Now we need to be smarter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "atspy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
